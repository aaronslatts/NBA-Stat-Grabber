{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d653638a",
   "metadata": {},
   "source": [
    "Automated NBA Data Aggregator\n",
    "===============================\n",
    "This workshop is intended to bridge the gap between instructional Python programming and real-world sports analytics uses. The tutorial is interactive, in which students work step by step, which is ideal for a joint session of statistics students and basketball enthusiasts at a university hackathon or data science club session. The text assumes that students have been introduced to Python courses and understand programming concepts like loops, functions, and basic data structures, but now need to learn how these are used in real data processes in the real world.\n",
    "The approach mirrors my experience educating new analysts in sports tech startups, focusing on the subtle realities distinguishing classroom exercises from production settings. We will use real NBA statistics as our interesting case study, with tangible examples and internal relevance to students interested in sports. The tutorial puts the highest priority on practical API usage in theory because this is the most urgent need for those students who are entering into professional employment or more advanced projects.\n",
    "Good professional practice includes correctly implementing API rate limiting, using defensive programming patterns to sanitize data, dealing with configurations in different deployment environments, and generating output that is ready for analysis. All of these are precisely what set learning code exercises apart from production-level, maintainable systems. The workshop is structured so that students understand how to implement each component and why professional developers make certain architecture choices when processing sports data at scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faedd75",
   "metadata": {},
   "source": [
    "\n",
    "A comprehensive tool to fetch, process, and analyze NBA player statistics from the API-NBA via RapidAPI.\n",
    "\n",
    "Features:\n",
    "- Can be configured either interactively or via creds.py\n",
    "- Fetches season averages for all players on a specified team\n",
    "- Handles API rate limiting with configurable delays\n",
    "- Calculates advanced statistics (PPG, RPG, APG, FG%)\n",
    "- Outputs clean CSV files with proper error handling\n",
    "- Provides progress tracking and verbose logging\n",
    "\n",
    "Usage Options:\n",
    "1. Interactive Mode:\n",
    "   - Run the script and follow the prompts\n",
    "   - Enter all configuration when prompted\n",
    "\n",
    "2. Manual Configuration:\n",
    "   - Set your RapidAPI key in creds.py (RAPIDAPI_KEY = \"your-key-here\")\n",
    "   - Configure TEAM_NAME, SEASON, DELAY, and OUTPUT_DIR constants\n",
    "   - Run the script\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bae5bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "class NBADataFetcher:\n",
    "    \"\"\"Handles all NBA API interactions with proper error handling and rate limiting.\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str):\n",
    "        \"\"\"Initialize the fetcher with API credentials.\"\"\"\n",
    "        self.headers = {\n",
    "            \"X-RapidAPI-Key\": api_key,\n",
    "            \"X-RapidAPI-Host\": \"api-nba-v1.p.rapidapi.com\"\n",
    "        }\n",
    "    \n",
    "    def _make_api_request(self, endpoint: str, params: Dict = None) -> Optional[Dict]:\n",
    "        \"\"\"Generic API request handler with error handling and retries.\"\"\"\n",
    "        url = f\"https://api-nba-v1.p.rapidapi.com/{endpoint}\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, headers=self.headers, params=params, timeout=15)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"API request failed: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_team_id(self, team_name: str) -> Optional[int]:\n",
    "        \"\"\"Find team ID by name with fuzzy matching.\"\"\"\n",
    "        data = self._make_api_request(\"teams\")\n",
    "        if not data or \"response\" not in data:\n",
    "            return None\n",
    "            \n",
    "        for team in data[\"response\"]:\n",
    "            if team_name.lower() in team[\"name\"].lower():\n",
    "                print(f\"Found team: {team['name']} (ID: {team['id']})\")\n",
    "                return team[\"id\"]\n",
    "        return None\n",
    "    \n",
    "    def get_team_players(self, team_id: int, season: str) -> List[Dict]:\n",
    "        \"\"\"Retrieve all players for a given team and season.\"\"\"\n",
    "        params = {\"team\": team_id, \"season\": season}\n",
    "        data = self._make_api_request(\"players\", params)\n",
    "        return data.get(\"response\", []) if data else []\n",
    "    \n",
    "    def get_player_stats(self, player_id: int, player_name: str, season: str) -> Optional[Dict]:\n",
    "        \"\"\"Fetch and calculate season averages for a player.\"\"\"\n",
    "        params = {\"id\": player_id, \"season\": season}\n",
    "        data = self._make_api_request(\"players/statistics\", params)\n",
    "        if not data or \"response\" not in data:\n",
    "            return None\n",
    "            \n",
    "        game_logs = data[\"response\"]\n",
    "        return self._calculate_averages(game_logs, player_name)\n",
    "    \n",
    "    def _calculate_averages(self, game_logs: List[Dict], player_name: str) -> Dict:\n",
    "        \"\"\"Calculate season averages from game logs with validation.\"\"\"\n",
    "        played_games = [g for g in game_logs if g.get(\"min\") not in [None, \"00:00\", \"\"]]\n",
    "        games_played = len(played_games)\n",
    "        \n",
    "        if games_played == 0:\n",
    "            print(f\"No played games found for {player_name}\")\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            points = sum(float(g.get(\"points\", 0)) for g in played_games)\n",
    "            rebounds = sum(float(g.get(\"totReb\", 0)) for g in played_games)\n",
    "            assists = sum(float(g.get(\"assists\", 0)) for g in played_games)\n",
    "            fgm = sum(float(g.get(\"fgm\", 0)) for g in played_games)\n",
    "            fga = sum(float(g.get(\"fga\", 0)) for g in played_games)\n",
    "            \n",
    "            return {\n",
    "                \"name\": player_name,\n",
    "                \"ppg\": round(points / games_played, 1),\n",
    "                \"rpg\": round(rebounds / games_played, 1),\n",
    "                \"apg\": round(assists / games_played, 1),\n",
    "                \"fg_pct\": round(fgm / fga, 3) if fga > 0 else 0.0,\n",
    "                \"games_played\": games_played,\n",
    "                \"total_games\": len(game_logs),\n",
    "                \"last_updated\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            }\n",
    "        except (TypeError, ValueError) as e:\n",
    "            print(f\"Error calculating stats for {player_name}: {e}\")\n",
    "            return None\n",
    "\n",
    "class DataExporter:\n",
    "    \"\"\"Handles data export operations with proper file management.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_to_csv(data: List[Dict], filename: str, output_dir: str = \"output\") -> bool:\n",
    "        \"\"\"Save player statistics to CSV with error handling.\"\"\"\n",
    "        if not data:\n",
    "            print(\"No data to save\")\n",
    "            return False\n",
    "            \n",
    "        fieldnames = [\n",
    "            \"name\", \"ppg\", \"rpg\", \"apg\", \"fg_pct\", \n",
    "            \"games_played\", \"total_games\", \"last_updated\"\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            filepath = os.path.join(output_dir, filename)\n",
    "            with open(filepath, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "                writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "                writer.writeheader()\n",
    "                writer.writerows(data)\n",
    "            print(f\"Successfully saved data to {filepath}\")\n",
    "            return True\n",
    "        except (IOError, csv.Error) as e:\n",
    "            print(f\"Failed to save CSV: {e}\")\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877f918d",
   "metadata": {},
   "source": [
    "Introduction: The API-Driven Analytics Pipeline\n",
    "===============================================\n",
    "\n",
    "Current basketball analytics have a scope that makes it impossible to collect data manually. Consider the data footprint of a single NBA team during the 2024 season aloneâ€”82 regular-season games, with 15 players playing 25+ minutes per game and over 50 statistics gathered per player per game. This translates to 30 teams at the league level, which generates millions of data points across thousands of games each season. Traditional manual data collection methods cannot handle this volume while maintaining the accuracy and timeliness required for meaningful analysis.\n",
    "\n",
    "Our solution automates this process with three basic technical elements that mimic the infrastructure of professional sports leagues. First, we have professional-grade API integration far beyond HTTP request simplicity. Production-grade API use includes secure authentication via RapidAPI keys, parameter-based endpoint construction for excellent data filtering accuracy, and strict enforcement of rate limits to avoid service interruption. The system should also have network resilience features like automatic retries with exponential backoff and adequate timeouts - real-world APIs tend to experience occasional outages or slowdowns that academic examples typically ignore.\n",
    "\n",
    "Second, we provide an end-to-end data quality layer to check the unsightly aspects of raw sports data. API returns typically include \"Did Not Play\" records that would inflate averages if they are not dropped, truncated data feeds that include missing information, and type differences where numbers sometimes appear as strings or null fields. Our validation pipeline addresses these issues by employing active participation filtering, robust type conversion guards, and statistical sanity checks that ensure only valid data proceeds to analysis.\n",
    "Third, we possess a production-grade output system that generates the clean, normalized forms analysts handle in their procedures. These are properly formatted CSV files with consistent schemas, encapsulated metadata like processing timestamps, and error-protected file operations that elegantly handle permission issues and storage capacities. The output system supports configurable storage locations and file naming schemes to satisfy organizational needs.\n",
    "\n",
    "This structure closely mirrors that used by NBA team analytics personnel, sports media outlets like ESPN, and sites using advanced statistics like FiveThirtyEight. The advantages of automation are compellingâ€”where it can take days of tedium to process manually, our pipeline can construct full-season data in minutes. Above all, automation eliminates whole categories of human transcription errors while maintaining flawless consistency with official NBA calculation metrics.\n",
    "\n",
    "Our practice goes beyond ordinary academic examples by employing professional development idioms like type hints for readability, dynamic configuration parameters for different deployment profiles, and detailed progress logging for long-running operations. Such idioms are usual in production code but rare in course materials. For instance, whereas an incoming player might calculate points per game via a straightforward division arithmetic operation, we employ suitably encapsulated functions that validate all inputs, deal well with edge situations, and produce results that adhere to professional standards for formatting and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc5d717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config_interactive() -> Dict:\n",
    "    \"\"\"Collect and validate all user input parameters for interactive mode.\"\"\"\n",
    "    print(\"\\nNBA Player Statistics Aggregator - Interactive Configuration\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    config = {}\n",
    "    \n",
    "    # Get API Key\n",
    "    while True:\n",
    "        config['api_key'] = input(\"\\nEnter your RapidAPI key: \").strip()\n",
    "        if config['api_key']:\n",
    "            break\n",
    "        print(\"API key cannot be empty. Please try again.\")\n",
    "    \n",
    "    # Get Team Name\n",
    "    while True:\n",
    "        config['team_name'] = input(\"\\nEnter team name (e.g., 'Lakers', 'Warriors'): \").strip()\n",
    "        if config['team_name']:\n",
    "            break\n",
    "        print(\"Team name cannot be empty. Please try again.\")\n",
    "    \n",
    "    # Get Season Year\n",
    "    while True:\n",
    "        season = input(\"\\nEnter season year (e.g., 2023 for 2022-23 season): \").strip()\n",
    "        if season.isdigit() and len(season) == 4:\n",
    "            config['season'] = season\n",
    "            break\n",
    "        print(\"Invalid season. Please enter a 4-digit year (e.g., 2023).\")\n",
    "    \n",
    "    # Get API Delay\n",
    "    while True:\n",
    "        delay = input(\"\\nEnter API delay in seconds (recommended 1-5 to avoid rate limiting): \").strip()\n",
    "        try:\n",
    "            config['delay'] = max(0.5, float(delay))  # Minimum 0.5 second delay\n",
    "            break\n",
    "        except ValueError:\n",
    "            print(\"Invalid delay. Please enter a number (e.g., 2 for 2 seconds).\")\n",
    "    \n",
    "    # Get Output Directory\n",
    "    config['output_dir'] = input(\"\\nEnter output directory (press Enter for default 'output'): \").strip()\n",
    "    if not config['output_dir']:\n",
    "        config['output_dir'] = \"output\"\n",
    "    \n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e1328c",
   "metadata": {},
   "source": [
    "Core Concepts Explained\n",
    "=======================\n",
    "Three fundamental concepts form the foundation of our professional NBA statistics processor, each solving fundamental aspects of production data systems. Knowledge of these concepts will help participants adapt the pipeline to other sports or analytical purposes beyond basketball.\n",
    "\n",
    "The first pillar is professional API patterns and integration protocols. Working with production APIs is more than sending straightforward HTTP requests - it is all about deliberate thought around authentication, parameterization, and operational constraints. Our system incorporates secure authentication in properly formatted headers containing the RapidAPI key for service entry and focused host data for endpoint routing. These headers must be appended to every request with the strict format constraints. Equally critical is the strategic use of query parameters that enable exact filtering of the data we bring down. Parameters enable filtering by season, year, specific teams or players, ranges of dates, and other dimensions that prevent downloading extraneous data. A well-parameterized design achieves a tremendous performance and reliability improvement by reducing payload sizes and looking only at relevant records.\n",
    "\n",
    "The second underlying principle is rigorous data validation and quality assurance. Raw sports data from APIs frequently contains artifacts and inconsistencies that will skew analysis unless dealt with properly. Our validation pipeline involves several layers of quality tests, starting with participation filtering to remove records for games where a player did not participate. This includes removing \"Did Not Play\" designations, games played with zero minutes, and cases where players were on the roster but scratched at a coach's discretion. The system then performs extensive type safety checks, so numeric statistics arrive as proper numbers, not strings or null values. Text fields like player names have uniform formatting. Range checking adds another quality layer by flagging statistically improbable values that might indicate data corruption - a basketball player cannot legitimately score 200 points during a game.\n",
    "\n",
    "The third pillar is strict compliance with official NBA statistical protocols and reporting standards. Basic statistics like points per game (PPG) may seem simple in theory, but professional usage requires attention to detail, which is usually not emphasized in academic settings. The NBA has specific norms for rounding statistical outcomes (generally to a single decimal point for per-game averages), handling edge cases like division by zero when calculating percentages, and qualifying statistics using minimum activity thresholds. More advanced statistics introduce additional complexity via expert algorithms for metrics like actual shooting percentage (accounting for the differential value of three-pointers and free throws) and player efficiency rating (a weighted sum of several statistics). Our implementation mirrors how NBA clubs and media calculate and report these statistics, so our results will be easily comparable to authoritative sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6ec338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config_manual() -> Dict:\n",
    "    \"\"\"Load configuration from creds.py and constants for manual mode.\"\"\"\n",
    "    try:\n",
    "        import creds\n",
    "        api_key = creds.RAPIDAPI_KEY\n",
    "    except (ImportError, AttributeError) as e:\n",
    "        raise ValueError(\"Missing or invalid creds.py file. Please create one with your RapidAPI key.\") from e\n",
    "    \n",
    "    # These would be defined at the top of the file in manual mode\n",
    "    config = {\n",
    "        'api_key': api_key,\n",
    "        'team_name': \"Lakers\",  # TEAM_NAME constant\n",
    "        'season': \"2023\",       # SEASON constant\n",
    "        'delay': 6,             # DELAY constant\n",
    "        'output_dir': \"output\"  # OUTPUT_DIR constant\n",
    "    }\n",
    "    \n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b64bb21",
   "metadata": {},
   "source": [
    "Building the Solution\n",
    "======================\n",
    "\n",
    "We construct the end-to-end data pipeline with three progressively sophisticated components, each demonstrating best-practice software engineering for data systems. With modular components, students can learn each component independently and see how they compose together.\n",
    "The first essential component is a solid API client for production work. Unlike the standard bare script-based API calls in tutorial examples, our client features several professional-grade aspects required for reliable operation. Connection management includes long-running sessions for improved performance between different requests, customizable timeouts to prevent hanging, and consistent treatment of headers and parameters for all calls. The client employs high-end fault tolerance with an exponential backoff retry mechanism. If a request is failing (which occurs with APIs of the real world), the system will automatically retry with longer and longer delays between attempts. This behavior elegantly handles momentary network issues or API rate limits without intervention. The client also includes complete error handling capable of distinguishing between different failure classes (network, auth, data validation failures) and processing each appropriately.\n",
    "\n",
    "Data sanitization is the other large piece, which normalizes raw API results into tidy, analysis-ready datasets. The sanitization engine begins with participation validation, only retaining data in cases where players had meaningful play in games. This involves validating minutes played thresholds (excluding zero or meaningless minutes games), verifying game status indicators, and cross-verifying roster information. The system then performs aggressive type conversion and validation, which puts all statistical values in good numeric shape with missing or malformed data processed sensibly. One nice touch of professionalism is support for reporting data quality - rather than silently discarding bad records, the system records validation failures with enough information that analysts can investigate potential problems in the data. This monitoring capability is critical in production environments where data quality issues might indicate larger system problems.\n",
    "\n",
    "According to official league procedures, the statistical processing engine is the third core component, computing standard and premium NBA statistics. The engine is structured as a sequence of specialist calculation modules, where each module can be individually updated and tested. Basic statistics modules carry out simple calculations like per-game averages for points, rebounds, and assists while following NBA rounding conventions and qualification levels. Advanced metrics modules use more advanced algorithms such as player efficiency rating (a weighted composite statistic), actual shooting percentage (with the value of the shot type included), and usage percentage (estimating what proportion of team possessions a player controls). The engine contains a configuration layer that controls what metrics are calculated and in what output format, allowing for customization for a range of analysis needs. Throughout all computation, the engine always maintains strict type consistency and possesses graceful edge cases, such as being capable of dealing with division operations where denominators might be zero.\n",
    "\n",
    "These components demonstrate several significant professional software engineering practices in production systems. Input validation at multiple levels demonstrates consistent error-handling patterns. The system demonstrates a clean separation of concerns based on modular design such that the parts can be tested and edited independently. Configuration management supports both interactive and file-based configurations for different usage patterns. Most of all, the implementation keeps maintainability in mind, using mindful naming, type hints, and docstrings - knowing that real-world code gets read and edited many times more than originally written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cff5ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_with_config(config: Dict):\n",
    "    \"\"\"Main execution flow using the provided configuration.\"\"\"\n",
    "    print(f\"\\nNBA Player Statistics Aggregator - {config['team_name']} {config['season']}\")\n",
    "    print(f\"Starting at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    # Initialize components\n",
    "    fetcher = NBADataFetcher(config['api_key'])\n",
    "    exporter = DataExporter()\n",
    "    \n",
    "    # Get team ID\n",
    "    print(f\"\\nSearching for team: {config['team_name']}...\")\n",
    "    team_id = fetcher.get_team_id(config['team_name'])\n",
    "    if not team_id:\n",
    "        print(f\"Could not find team: {config['team_name']}\")\n",
    "        print(\"Please check the team name and try again.\")\n",
    "        return\n",
    "    \n",
    "    # Get players\n",
    "    print(f\"\\nFetching players for {config['team_name']} {config['season']} season...\")\n",
    "    players = fetcher.get_team_players(team_id, config['season'])\n",
    "    if not players:\n",
    "        print(\"No players found for team\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nProcessing {len(players)} players...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eceb8ea",
   "metadata": {},
   "source": [
    "Complete System Walkthrough\n",
    "===========================\n",
    "\n",
    "The combined NBA analytics pipeline combines all aspects into an end-to-end system demonstrating professional data engineering techniques. This tour runs through the complete workflow from initialization to final output, emphasizing key design decisions and why they were made.\n",
    "\n",
    "System configuration is the foundation of operational flexibility. We have an interactive prompts mode for exploratory use and file-based configurations for automated processes in a dual-mode system configuration. The interactive mode helps users with parameter entry with validation and courteous feedback to ensure proper API keys, team identifiers, and sensible processing parameters. File-based configuration is based on a production setup credentials file, settings module, and unattended scheduled jobs and analysis applications. The configuration manager handles Sensitive data correctly, never logging or displaying API keys in plain text but giving helpful error messages for bad settings. This two-way strategy caters to the whole gamut of usage scenarios from one-off analysis to report automation systems.\n",
    "\n",
    "Data gathering begins with team resolution, converting human-readable team names (\"Los Angeles Lakers\") into the internal team IDs that the API employs. Team resolution employs fuzzy matching to handle typical name variants (\"Lakers\" vs \"LA Lakers\") and provides beneficial feedback when matches are ambiguous. Once the team is identified, the system downloads roster information to determine whom to examine and imports game logs for all players within the specified season. The fetcher imposes strict rate limiting and stifles requests to keep neatly under API limits with the best throughput. A progress monitor provides accessible feedback on long operations, but another benefit, touch, is often absent in learning samples. After acquisition, the system permits exhaustive logging, facilitating debugging and usage auditing without leaking sensitive credentials.\n",
    "\n",
    "Data processing converts raw game logs to analysis results through several steps. Early validation rejects incomplete or damaged records and logs quality issues that will be reviewed later. The system computes base statistics such as points per game, rebounds per game, assists per game, rounded NBA-fashion, and qualifying players by playing level. Calculation of advanced metrics proceeds, with each metric embedded in its function to facilitate maintenance ease. The processing engine can easily calculate derived fields like shooting percentages and efficiency metrics while calculating all edge cases, like correctly calculating field goal percentage for players who have not attempted any shots yet. Data lineage information about how each metric was calculated from what source data is retained during processing for analytical integrity during commercial deployment.\n",
    "\n",
    "Output generation produces analysis-ready output in a directly consumable form. The primary output is neatly formatted CSV files with player statistics that have consistent column names and are in order to industry requirements. Files include metadata headers for generation timestamp, data source, and processing parameters for aiding version control. The exporter has robust file handling with correct permissions, atomic write patterns for preventing partial outputs, and parameterizable destination paths. The system normalizes data into forms for integrated database environments that map well into relational schemas. Output file naming is deterministic with team, season, and date information for easy organization. The exporter provides validation checks that files were written out in their entirety and correctly before reporting successful completion.\n",
    "\n",
    "The flow of execution orchestrates all components into a single pipeline. Initialization loads and verifies the configuration while establishing necessary resources and connections. The collection gathering phase gathers roster information and game logs with chunking and pacing appropriate for high data sets. Processing transforms raw data into a processed state through validation, statistical computation, and quality check stages. Export generates permanent output while dropping temporary resources. The pipeline uses status monitoring with satisfactory progress and issue feedback in every operation. Error handling differentiates between transient errors (like network blips) that can be retried and fatal errors (like bad credentials) that require intervention by the user. The pipeline is designed for interactive use in exploratory analysis and programmatic integration into larger data pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3657c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each player\n",
    "    player_stats = []\n",
    "    for i, player in enumerate(players, 1):\n",
    "        first_name = player.get(\"firstname\", \"\").strip()\n",
    "        last_name = player.get(\"lastname\", \"\").strip()\n",
    "        player_name = f\"{first_name} {last_name}\" if first_name or last_name else \"Unknown Player\"\n",
    "        player_id = player.get(\"id\")\n",
    "        \n",
    "        if not player_id:\n",
    "            print(f\"Skipping player with missing ID: {player_name}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n{i}/{len(players)}: Processing {player_name}...\")\n",
    "        \n",
    "        stats = fetcher.get_player_stats(player_id, player_name, config['season'])\n",
    "        if stats:\n",
    "            player_stats.append(stats)\n",
    "            print(f\"  â†’ {stats['ppg']} PPG, {stats['rpg']} RPG, {stats['apg']} APG\")\n",
    "            print(f\"  â†’ FG%: {stats['fg_pct']:.1%} ({stats['games_played']}/{stats['total_games']} games)\")\n",
    "        \n",
    "        # Respect rate limits\n",
    "        if i < len(players):\n",
    "            time.sleep(config['delay'])\n",
    "    \n",
    "    # Export results\n",
    "    if player_stats:\n",
    "        filename = f\"{config['team_name'].lower().replace(' ', '_')}_{config['season']}_stats.csv\"\n",
    "        exporter.save_to_csv(player_stats, filename, config['output_dir'])\n",
    "        \n",
    "        print(\"\\nProcess completed successfully!\")\n",
    "        print(f\"\\nSummary:\")\n",
    "        print(f\"- Team: {config['team_name']}\")\n",
    "        print(f\"- Season: {config['season']}\")\n",
    "        print(f\"- Players processed: {len(player_stats)}/{len(players)}\")\n",
    "        print(f\"- Output file: {os.path.join(config['output_dir'], filename)}\")\n",
    "    else:\n",
    "        print(\"\\nProcess completed but no valid player statistics were collected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66af9cfd",
   "metadata": {},
   "source": [
    "Conclusion and Next Steps\n",
    "=========================\n",
    "\n",
    "This workshop has equipped participants to build professional-grade sports analytics pipelines beyond classroom exercises. The techniques and themes demonstrated are not limited to basketball but to any data-intensive discipline requiring substantial collection, processing, and analysis of significant statistics. The pipeline's modular structure provides several natural extensions that would be excellent follow-up projects for students wishing to expand their knowledge.\n",
    "\n",
    "Expanding the statistical arsenal offers one beneficial area of enhancement. The system could include advanced defensive statistics like defensive rating or steal percentage, lineup analysis tracking group performance for given player pairings, or even prognostic model components projecting future performance from historical trends. Each further category of new statistics would support the principles of good statistical use while enhancing the system's value as an analytical tool.\n",
    "\n",
    "Technical add-ons would convert the pipeline into a more complex platform. Integration with a database would allow for permanent storage of historical statistics to enable longitudinal analysis. A visual layer could generate charts and reports from processed information. Automatic reporting capabilities could issue daily or weekly reports to coaching staff or the media. Web service encapsulation would expose access to the system's features remotely over REST APIs. These enhancements would demonstrate how analytical pipelines integrate into larger organizational contexts.\n",
    "\n",
    "Professional development techniques offer another space for growth. Facilitating a complete test environment with unit tests for each calculation module and integration tests for the whole pipeline would guarantee software engineering best practices. Performance benchmarking would identify areas for optimization throughout the data processing pipeline. An environment setup with continuous integration would demonstrate state-of-the-art DevOps best practices for analysis systems. Documentation generation would provide professional-grade reference material for system maintainers and end users.\n",
    "\n",
    "The knowledge acquired through this workshop has direct applications in the whole range of careers in sports technology. Teams' analytics departments value professionals who understand statistical methodologies and their reliable implementation. League information needs to be handled by engineers in the form of engaging visualizations and stories for media outlets. Fantasy sports and sports betting analysis require robust pipes that handle fast-evolving data. Talent evaluation relies on real-time, accurate statistics from player rating services. Perhaps most importantly, these trends are relevant to countless domains beyond sports - any field that deals with vast quantities of fast-changing data can learn from the same master engineering methods.\n",
    "\n",
    "The complete solution demonstrates how classroom programming concepts mature into industrial data systems by considering reliability, maintainability, and reality constraints. Students gain specific technical skills and the mindset to build production-quality analytical tools. This process of evolving from academic exercise to professional work is a critical milestone in any data-driven career path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422578d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main entry point with mode selection.\"\"\"\n",
    "    print(\"\\nNBA Player Statistics Aggregator\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    try:\n",
    "        # Let user choose between interactive and manual mode\n",
    "        while True:\n",
    "            mode = input(\"\\nChoose mode:\\n1. Interactive (enter configuration now)\\n2. Manual (use creds.py and constants)\\nEnter choice (1 or 2): \").strip()\n",
    "            if mode in ('1', '2'):\n",
    "                break\n",
    "            print(\"Invalid choice. Please enter 1 or 2.\")\n",
    "        \n",
    "        if mode == '1':\n",
    "            config = get_config_interactive()\n",
    "        else:\n",
    "            config = get_config_manual()\n",
    "        \n",
    "        run_with_config(config)\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\nProcess interrupted by user. Exiting...\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred: {e}\")\n",
    "    finally:\n",
    "        print(\"\\nThank you for using the NBA Player Statistics Aggregator!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b73569",
   "metadata": {},
   "source": [
    "Full Script\n",
    "==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768bdba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "class NBADataFetcher:\n",
    "    \"\"\"Handles all NBA API interactions with proper error handling and rate limiting.\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str):\n",
    "        \"\"\"Initialize the fetcher with API credentials.\"\"\"\n",
    "        self.headers = {\n",
    "            \"X-RapidAPI-Key\": api_key,\n",
    "            \"X-RapidAPI-Host\": \"api-nba-v1.p.rapidapi.com\"\n",
    "        }\n",
    "    \n",
    "    def _make_api_request(self, endpoint: str, params: Dict = None) -> Optional[Dict]:\n",
    "        \"\"\"Generic API request handler with error handling and retries.\"\"\"\n",
    "        url = f\"https://api-nba-v1.p.rapidapi.com/{endpoint}\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, headers=self.headers, params=params, timeout=15)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"API request failed: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_team_id(self, team_name: str) -> Optional[int]:\n",
    "        \"\"\"Find team ID by name with fuzzy matching.\"\"\"\n",
    "        data = self._make_api_request(\"teams\")\n",
    "        if not data or \"response\" not in data:\n",
    "            return None\n",
    "            \n",
    "        for team in data[\"response\"]:\n",
    "            if team_name.lower() in team[\"name\"].lower():\n",
    "                print(f\"Found team: {team['name']} (ID: {team['id']})\")\n",
    "                return team[\"id\"]\n",
    "        return None\n",
    "    \n",
    "    def get_team_players(self, team_id: int, season: str) -> List[Dict]:\n",
    "        \"\"\"Retrieve all players for a given team and season.\"\"\"\n",
    "        params = {\"team\": team_id, \"season\": season}\n",
    "        data = self._make_api_request(\"players\", params)\n",
    "        return data.get(\"response\", []) if data else []\n",
    "    \n",
    "    def get_player_stats(self, player_id: int, player_name: str, season: str) -> Optional[Dict]:\n",
    "        \"\"\"Fetch and calculate season averages for a player.\"\"\"\n",
    "        params = {\"id\": player_id, \"season\": season}\n",
    "        data = self._make_api_request(\"players/statistics\", params)\n",
    "        if not data or \"response\" not in data:\n",
    "            return None\n",
    "            \n",
    "        game_logs = data[\"response\"]\n",
    "        return self._calculate_averages(game_logs, player_name)\n",
    "    \n",
    "    def _calculate_averages(self, game_logs: List[Dict], player_name: str) -> Dict:\n",
    "        \"\"\"Calculate season averages from game logs with validation.\"\"\"\n",
    "        played_games = [g for g in game_logs if g.get(\"min\") not in [None, \"00:00\", \"\"]]\n",
    "        games_played = len(played_games)\n",
    "        \n",
    "        if games_played == 0:\n",
    "            print(f\"No played games found for {player_name}\")\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            points = sum(float(g.get(\"points\", 0)) for g in played_games)\n",
    "            rebounds = sum(float(g.get(\"totReb\", 0)) for g in played_games)\n",
    "            assists = sum(float(g.get(\"assists\", 0)) for g in played_games)\n",
    "            fgm = sum(float(g.get(\"fgm\", 0)) for g in played_games)\n",
    "            fga = sum(float(g.get(\"fga\", 0)) for g in played_games)\n",
    "            \n",
    "            return {\n",
    "                \"name\": player_name,\n",
    "                \"ppg\": round(points / games_played, 1),\n",
    "                \"rpg\": round(rebounds / games_played, 1),\n",
    "                \"apg\": round(assists / games_played, 1),\n",
    "                \"fg_pct\": round(fgm / fga, 3) if fga > 0 else 0.0,\n",
    "                \"games_played\": games_played,\n",
    "                \"total_games\": len(game_logs),\n",
    "                \"last_updated\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            }\n",
    "        except (TypeError, ValueError) as e:\n",
    "            print(f\"Error calculating stats for {player_name}: {e}\")\n",
    "            return None\n",
    "\n",
    "class DataExporter:\n",
    "    \"\"\"Handles data export operations with proper file management.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_to_csv(data: List[Dict], filename: str, output_dir: str = \"output\") -> bool:\n",
    "        \"\"\"Save player statistics to CSV with error handling.\"\"\"\n",
    "        if not data:\n",
    "            print(\"No data to save\")\n",
    "            return False\n",
    "            \n",
    "        fieldnames = [\n",
    "            \"name\", \"ppg\", \"rpg\", \"apg\", \"fg_pct\", \n",
    "            \"games_played\", \"total_games\", \"last_updated\"\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            filepath = os.path.join(output_dir, filename)\n",
    "            with open(filepath, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "                writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "                writer.writeheader()\n",
    "                writer.writerows(data)\n",
    "            print(f\"Successfully saved data to {filepath}\")\n",
    "            return True\n",
    "        except (IOError, csv.Error) as e:\n",
    "            print(f\"Failed to save CSV: {e}\")\n",
    "            return False\n",
    "\n",
    "def get_config_interactive() -> Dict:\n",
    "    \"\"\"Collect and validate all user input parameters for interactive mode.\"\"\"\n",
    "    print(\"\\nNBA Player Statistics Aggregator - Interactive Configuration\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    config = {}\n",
    "    \n",
    "    # Get API Key\n",
    "    while True:\n",
    "        config['api_key'] = input(\"\\nEnter your RapidAPI key: \").strip()\n",
    "        if config['api_key']:\n",
    "            break\n",
    "        print(\"API key cannot be empty. Please try again.\")\n",
    "    \n",
    "    # Get Team Name\n",
    "    while True:\n",
    "        config['team_name'] = input(\"\\nEnter team name (e.g., 'Lakers', 'Warriors'): \").strip()\n",
    "        if config['team_name']:\n",
    "            break\n",
    "        print(\"Team name cannot be empty. Please try again.\")\n",
    "    \n",
    "    # Get Season Year\n",
    "    while True:\n",
    "        season = input(\"\\nEnter season year (e.g., 2023 for 2022-23 season): \").strip()\n",
    "        if season.isdigit() and len(season) == 4:\n",
    "            config['season'] = season\n",
    "            break\n",
    "        print(\"Invalid season. Please enter a 4-digit year (e.g., 2023).\")\n",
    "    \n",
    "    # Get API Delay\n",
    "    while True:\n",
    "        delay = input(\"\\nEnter API delay in seconds (recommended 1-5 to avoid rate limiting): \").strip()\n",
    "        try:\n",
    "            config['delay'] = max(0.5, float(delay))  # Minimum 0.5 second delay\n",
    "            break\n",
    "        except ValueError:\n",
    "            print(\"Invalid delay. Please enter a number (e.g., 2 for 2 seconds).\")\n",
    "    \n",
    "    # Get Output Directory\n",
    "    config['output_dir'] = input(\"\\nEnter output directory (press Enter for default 'output'): \").strip()\n",
    "    if not config['output_dir']:\n",
    "        config['output_dir'] = \"output\"\n",
    "    \n",
    "    return config\n",
    "\n",
    "def get_config_manual() -> Dict:\n",
    "    \"\"\"Load configuration from creds.py and constants for manual mode.\"\"\"\n",
    "    try:\n",
    "        import creds\n",
    "        api_key = creds.RAPIDAPI_KEY\n",
    "    except (ImportError, AttributeError) as e:\n",
    "        raise ValueError(\"Missing or invalid creds.py file. Please create one with your RapidAPI key.\") from e\n",
    "    \n",
    "    # These would be defined at the top of the file in manual mode\n",
    "    config = {\n",
    "        'api_key': api_key,\n",
    "        'team_name': \"Lakers\",  # TEAM_NAME constant\n",
    "        'season': \"2023\",       # SEASON constant\n",
    "        'delay': 6,             # DELAY constant\n",
    "        'output_dir': \"output\"  # OUTPUT_DIR constant\n",
    "    }\n",
    "    \n",
    "    return config\n",
    "\n",
    "def run_with_config(config: Dict):\n",
    "    \"\"\"Main execution flow using the provided configuration.\"\"\"\n",
    "    print(f\"\\nNBA Player Statistics Aggregator - {config['team_name']} {config['season']}\")\n",
    "    print(f\"Starting at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    # Initialize components\n",
    "    fetcher = NBADataFetcher(config['api_key'])\n",
    "    exporter = DataExporter()\n",
    "    \n",
    "    # Get team ID\n",
    "    print(f\"\\nSearching for team: {config['team_name']}...\")\n",
    "    team_id = fetcher.get_team_id(config['team_name'])\n",
    "    if not team_id:\n",
    "        print(f\"Could not find team: {config['team_name']}\")\n",
    "        print(\"Please check the team name and try again.\")\n",
    "        return\n",
    "    \n",
    "    # Get players\n",
    "    print(f\"\\nFetching players for {config['team_name']} {config['season']} season...\")\n",
    "    players = fetcher.get_team_players(team_id, config['season'])\n",
    "    if not players:\n",
    "        print(\"No players found for team\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nProcessing {len(players)} players...\")\n",
    "    \n",
    "    # Process each player\n",
    "    player_stats = []\n",
    "    for i, player in enumerate(players, 1):\n",
    "        first_name = player.get(\"firstname\", \"\").strip()\n",
    "        last_name = player.get(\"lastname\", \"\").strip()\n",
    "        player_name = f\"{first_name} {last_name}\" if first_name or last_name else \"Unknown Player\"\n",
    "        player_id = player.get(\"id\")\n",
    "        \n",
    "        if not player_id:\n",
    "            print(f\"Skipping player with missing ID: {player_name}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n{i}/{len(players)}: Processing {player_name}...\")\n",
    "        \n",
    "        stats = fetcher.get_player_stats(player_id, player_name, config['season'])\n",
    "        if stats:\n",
    "            player_stats.append(stats)\n",
    "            print(f\"  â†’ {stats['ppg']} PPG, {stats['rpg']} RPG, {stats['apg']} APG\")\n",
    "            print(f\"  â†’ FG%: {stats['fg_pct']:.1%} ({stats['games_played']}/{stats['total_games']} games)\")\n",
    "        \n",
    "        # Respect rate limits\n",
    "        if i < len(players):\n",
    "            time.sleep(config['delay'])\n",
    "    \n",
    "    # Export results\n",
    "    if player_stats:\n",
    "        filename = f\"{config['team_name'].lower().replace(' ', '_')}_{config['season']}_stats.csv\"\n",
    "        exporter.save_to_csv(player_stats, filename, config['output_dir'])\n",
    "        \n",
    "        print(\"\\nProcess completed successfully!\")\n",
    "        print(f\"\\nSummary:\")\n",
    "        print(f\"- Team: {config['team_name']}\")\n",
    "        print(f\"- Season: {config['season']}\")\n",
    "        print(f\"- Players processed: {len(player_stats)}/{len(players)}\")\n",
    "        print(f\"- Output file: {os.path.join(config['output_dir'], filename)}\")\n",
    "    else:\n",
    "        print(\"\\nProcess completed but no valid player statistics were collected.\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main entry point with mode selection.\"\"\"\n",
    "    print(\"\\nNBA Player Statistics Aggregator\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    try:\n",
    "        # Let user choose between interactive and manual mode\n",
    "        while True:\n",
    "            mode = input(\"\\nChoose mode:\\n1. Interactive (enter configuration now)\\n2. Manual (use creds.py and constants)\\nEnter choice (1 or 2): \").strip()\n",
    "            if mode in ('1', '2'):\n",
    "                break\n",
    "            print(\"Invalid choice. Please enter 1 or 2.\")\n",
    "        \n",
    "        if mode == '1':\n",
    "            config = get_config_interactive()\n",
    "        else:\n",
    "            config = get_config_manual()\n",
    "        \n",
    "        run_with_config(config)\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\nProcess interrupted by user. Exiting...\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred: {e}\")\n",
    "    finally:\n",
    "        print(\"\\nThank you for using the NBA Player Statistics Aggregator!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
