{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ffa9455",
   "metadata": {},
   "source": [
    "Instructor Context\n",
    "===================\n",
    "\n",
    "This workshop is intended to bridge the gap between instructional Python programming and real-world sports analytics uses. The tutorial is interactive, in which students work step by step, which is ideal for a joint session of statistics students and basketball enthusiasts at a university hackathon or data science club session. The text assumes that students have been introduced to Python courses and understand programming concepts like loops, functions, and basic data structures, but now need to learn how these are used in real data processes in the real world.\n",
    "\n",
    "The approach mirrors my experience educating new analysts in sports, or even small tech startups, focusing on the subtle realities distinguishing classroom exercises from production settings. We will use real NBA statistics as our interesting case study, with tangible examples and internal relevance to students interested in sports. The tutorial puts the highest priority on practical API usage in theory because this is the most urgent need for those students who are entering into professional employment or more advanced projects.\n",
    "Good professional practice includes correctly implementing API rate limiting, using defensive programming patterns to sanitize data, dealing with configurations in different deployment environments, and generating output that is ready for analysis. All of these are precisely what set learning code exercises apart from production-level, maintainable systems. The workshop is structured so that students understand how to implement each component and why professional developers make certain architecture choices when processing sports data at scale.\n",
    "\n",
    "Introduction: The API-Driven Analytics Pipeline\n",
    "================================================\n",
    "\n",
    "Current basketball analytics have a scope that makes it impossible to collect data manually. Consider the data footprint of a single NBA team during the 2024 season alone—82 regular-season games, with 15 players playing 25+ minutes per game and over 50 statistics gathered per player per game. This translates to 30 teams at the league level, which generates millions of data points across thousands of games each season. Traditional manual data collection methods cannot handle this volume while maintaining the accuracy and timeliness required for meaningful analysis.\n",
    "\n",
    "Our solution automates this process with three basic technical elements that mimic the infrastructure of professional sports leagues. First, we have professional-grade API integration far beyond HTTP request simplicity. Production-grade API use includes secure authentication via RapidAPI keys, parameter-based endpoint construction for excellent data filtering accuracy, and strict enforcement of rate limits to avoid service interruption. The system should also have network resilience features like automatic retries with exponential backoff and adequate timeouts - real-world APIs tend to experience occasional outages or slowdowns that academic examples typically ignore.\n",
    "\n",
    "Second, we provide an end-to-end data quality layer to check the unsightly aspects of raw sports data. API returns typically include \"Did Not Play\" records that would inflate averages if they are not dropped, truncated data feeds that include missing information, and type differences where numbers sometimes appear as strings or null fields. Our validation pipeline addresses these issues by employing active participation filtering, robust type conversion guards, and statistical sanity checks that ensure only valid data proceeds to analysis.\n",
    "\n",
    "Third, we possess a production-grade output system that generates the clean, normalized forms analysts handle in their procedures. These are properly formatted CSV files with consistent schemas, encapsulated metadata like processing timestamps, and error-protected file operations that elegantly handle permission issues and storage capacities. The output system supports configurable storage locations and file naming schemes to satisfy organizational needs.\n",
    "\n",
    "This structure closely mirrors that used by NBA team analytics personnel, sports media outlets like ESPN, and sites using advanced statistics like FiveThirtyEight. The advantages of automation are compelling—where it can take days of tedium to process manually, our pipeline can construct full-season data in minutes. Above all, automation eliminates whole categories of human transcription errors while maintaining flawless consistency with official NBA calculation metrics.\n",
    "\n",
    "Our practice goes beyond ordinary academic examples by employing professional development idioms like type hints for readability, dynamic configuration parameters for different deployment profiles, and detailed progress logging for long-running operations. Such idioms are usual in production code but rare in course materials. For instance, whereas an incoming player might calculate points per game via a straightforward division arithmetic operation, we employ suitably encapsulated functions that validate all inputs, deal well with edge situations, and produce results that adhere to professional standards for formatting and metadata.\n",
    "\n",
    "Core Concepts Explained\n",
    "=======================\n",
    "\n",
    "Three fundamental concepts form the foundation of our professional NBA statistics processor, each solving fundamental aspects of production data systems. Knowledge of these concepts will help participants adapt the pipeline to other sports or analytical purposes beyond basketball.\n",
    "\n",
    "The first pillar is professional API patterns and integration protocols. Working with production APIs is more than sending straightforward HTTP requests - it is all about deliberate thought around authentication, parameterization, and operational constraints. Our system incorporates secure authentication in properly formatted headers containing the RapidAPI key for service entry and focused host data for endpoint routing. These headers must be appended to every request with the strict format constraints. Equally critical is the strategic use of query parameters that enable exact filtering of the data we bring down. Parameters enable filtering by season, year, specific teams or players, ranges of dates, and other dimensions that prevent downloading extraneous data. A well-parameterized design achieves a tremendous performance and reliability improvement by reducing payload sizes and looking only at relevant records.\n",
    "\n",
    "The second underlying principle is rigorous data validation and quality assurance. Raw sports data from APIs frequently contains artifacts and inconsistencies that will skew analysis unless dealt with properly. Our validation pipeline involves several layers of quality tests, starting with participation filtering to remove records for games where a player did not participate. This includes removing \"Did Not Play\" designations, games played with zero minutes, and cases where players were on the roster but scratched at a coach's discretion. The system then performs extensive type safety checks, so numeric statistics arrive as proper numbers, not strings or null values. Text fields like player names have uniform formatting. Range checking adds another quality layer by flagging statistically improbable values that might indicate data corruption - a basketball player cannot legitimately score 200 points during a game.\n",
    "\n",
    "The third pillar is strict compliance with official NBA statistical protocols and reporting standards. Basic statistics like points per game (PPG) may seem simple in theory, but professional usage requires attention to detail, which is usually not emphasized in academic settings. The NBA has specific norms for rounding statistical outcomes (generally to a single decimal point for per-game averages), handling edge cases like division by zero when calculating percentages, and qualifying statistics using minimum activity thresholds. More advanced statistics introduce additional complexity via expert algorithms for metrics like actual shooting percentage (accounting for the differential value of three-pointers and free throws) and player efficiency rating (a weighted sum of several statistics). Our implementation mirrors how NBA clubs and media calculate and report these statistics, so our results will be easily comparable to authoritative sources.\n",
    "\n",
    "Building the Solution\n",
    "======================\n",
    "\n",
    "We construct the end-to-end data pipeline with three progressively sophisticated components, each demonstrating best-practice software engineering for data systems. With modular components, students can learn each component independently and see how they compose together.\n",
    "The first essential component is a solid API client for production work. Unlike the standard bare script-based API calls in tutorial examples, our client features several professional-grade aspects required for reliable operation. Connection management includes long-running sessions for improved performance between different requests, customizable timeouts to prevent hanging, and consistent treatment of headers and parameters for all calls. The client employs high-end fault tolerance with an exponential backoff retry mechanism. If a request is failing (which occurs with APIs of the real world), the system will automatically retry with longer and longer delays between attempts. This behavior elegantly handles momentary network issues or API rate limits without intervention. The client also includes complete error handling capable of distinguishing between different failure classes (network, auth, data validation failures) and processing each appropriately.\n",
    "\n",
    "Data sanitization is the other large piece, which normalizes raw API results into tidy, analysis-ready datasets. The sanitization engine begins with participation validation, only retaining data in cases where players had meaningful play in games. This involves validating minutes played thresholds (excluding zero or meaningless minutes games), verifying game status indicators, and cross-verifying roster information. The system then performs aggressive type conversion and validation, which puts all statistical values in good numeric shape with missing or malformed data processed sensibly. One nice touch of professionalism is support for reporting data quality - rather than silently discarding bad records, the system records validation failures with enough information that analysts can investigate potential problems in the data. This monitoring capability is critical in production environments where data quality issues might indicate larger system problems.\n",
    "\n",
    "According to official league procedures, the statistical processing engine is the third core component, computing standard and premium NBA statistics. The engine is structured as a sequence of specialist calculation modules, where each module can be individually updated and tested. Basic statistics modules carry out simple calculations like per-game averages for points, rebounds, and assists while following NBA rounding conventions and qualification levels. Advanced metrics modules use more advanced algorithms such as player efficiency rating (a weighted composite statistic), actual shooting percentage (with the value of the shot type included), and usage percentage (estimating what proportion of team possessions a player controls). The engine contains a configuration layer that controls what metrics are calculated and in what output format, allowing for customization for a range of analysis needs. Throughout all computation, the engine always maintains strict type consistency and possesses graceful edge cases, such as being capable of dealing with division operations where denominators might be zero.\n",
    "\n",
    "These components demonstrate several significant professional software engineering practices in production systems. Input validation at multiple levels demonstrates consistent error-handling patterns. The system demonstrates a clean separation of concerns based on modular design such that the parts can be tested and edited independently. Configuration management supports both interactive and file-based configurations for different usage patterns. Most of all, the implementation keeps maintainability in mind, using mindful naming, type hints, and docstrings - knowing that real-world code gets read and edited many times more than originally written.\n",
    "\n",
    "Complete System Walkthrough\n",
    "============================\n",
    "\n",
    "The combined NBA analytics pipeline combines all aspects into an end-to-end system demonstrating professional data engineering techniques. This tour runs through the complete workflow from initialization to final output, emphasizing key design decisions and why they were made.\n",
    "\n",
    "System configuration is the foundation of operational flexibility. We have an interactive prompts mode for exploratory use and file-based configurations for automated processes in a dual-mode system configuration. The interactive mode helps users with parameter entry with validation and courteous feedback to ensure proper API keys, team identifiers, and sensible processing parameters. File-based configuration is based on a production setup credentials file, settings module, and unattended scheduled jobs and analysis applications. The configuration manager handles Sensitive data correctly, never logging or displaying API keys in plain text but giving helpful error messages for bad settings. This two-way strategy caters to the whole gamut of usage scenarios from one-off analysis to report automation systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4b9483",
   "metadata": {},
   "source": [
    "Data gathering\n",
    "=============\n",
    " begins with team resolution, converting human-readable team names (\"Los Angeles Lakers\") into the internal team IDs that the API employs. Team resolution employs fuzzy matching to handle typical name variants (\"Lakers\" vs \"LA Lakers\") and provides beneficial feedback when matches are ambiguous. Once the team is identified, the system downloads roster information to determine whom to examine and imports game logs for all players within the specified season. The fetcher imposes strict rate limiting and stifles requests to keep neatly under API limits with the best throughput. A progress monitor provides accessible feedback on long operations, but another benefit, touch, is often absent in learning samples. After acquisition, the system permits exhaustive logging, facilitating debugging and usage auditing without leaking sensitive credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e08114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_config():\n",
    "    settings = {}\n",
    "    if not API_KEY:\n",
    "        settings['api_key'] = input(\"Drop your RapidAPI key here: \").strip()\n",
    "        if not settings['api_key']:\n",
    "            print(\"Can't continue without an API key :(\")\n",
    "            exit()\n",
    "    else:\n",
    "        settings['api_key'] = API_KEY\n",
    "        print(\"Found API key in creds.py!\")\n",
    "    \n",
    "    # get team\n",
    "    team = input(f\"Which team? (default: {TEAM_DEFAULT}): \").strip()\n",
    "    settings['team_name'] = team or TEAM_DEFAULT\n",
    "    \n",
    "    # season input validation\n",
    "    while True:\n",
    "        season = input(f\"What season? (default: {SEASON_DEFAULT}): \").strip() or SEASON_DEFAULT\n",
    "        if len(season) == 4 and season.isdigit():\n",
    "            settings['season'] = season\n",
    "            break\n",
    "        print(\"Need a 4-digit year!\")\n",
    "    \n",
    "    # api delay\n",
    "    while True:\n",
    "        delay = input(f\"Seconds between API calls (default: {WAIT_TIME}): \").strip() or str(WAIT_TIME)\n",
    "        try:\n",
    "            settings['delay'] = max(0.5, float(delay))  # at least half a second\n",
    "            break\n",
    "        except ValueError:\n",
    "            print(\"Numbers only please!\")\n",
    "    \n",
    "    return settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99289511",
   "metadata": {},
   "source": [
    "Data processing \n",
    "==================\n",
    "converts raw game logs to analysis results through several steps. Early validation rejects incomplete or damaged records and logs quality issues that will be reviewed later. The system computes base statistics such as points per game, rebounds per game, assists per game, rounded NBA-fashion, and qualifying players by playing level. Calculation of advanced metrics proceeds, with each metric embedded in its function to facilitate maintenance ease. The processing engine can easily calculate derived fields like shooting percentages and efficiency metrics while calculating all edge cases, like correctly calculating field goal percentage for players who have not attempted any shots yet. Data lineage information about how each metric was calculated from what source data is retained during processing for analytical integrity during commercial deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a8a9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_players(team_id, season):\n",
    "    #just get all players for a team\n",
    "    params = {\"team\": team_id, \"season\": season}\n",
    "    resp = hit_api(\"players\", params)\n",
    "    return resp.get('response', []) if resp else []\n",
    "\n",
    "def get_player_stats(pid, pname, season):\n",
    "    params = {\"id\": pid, \"season\": season}\n",
    "    resp = hit_api(\"players/statistics\", params)\n",
    "    if not resp:\n",
    "        return None\n",
    "    \n",
    "    # filter\n",
    "    games = resp.get('response', [])\n",
    "    real_games = [g for g in games if g.get('min') not in [None, \"00:00\", \"\"]]\n",
    "    \n",
    "    if not real_games:\n",
    "        print(f\"Looks like {pname} didn't play\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae28e92",
   "metadata": {},
   "source": [
    "Professional API Client\n",
    "=======================\n",
    "The hit_api() class encapsulates several production-quality API idioms. It does the following:\n",
    "Secured authentication through correctly formatted headers\n",
    "Base URL management for streamlined endpoint maintenance\n",
    "Timeout handling in order to avert hung processes\n",
    "Thorough error catching, which differentiates between various modes of failure\n",
    "JSON response normalization\n",
    "\n",
    "The API wrapper is simple but incorporates all the production-level reliability elements. Note how it returns None on error rather than raising exceptions to enable the calling code to utilize its error handling strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fe7d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_api(endpoint, params=None):\n",
    "    # basic api wrapper\n",
    "    base_url = \"https://api-nba-v1.p.rapidapi.com\"\n",
    "    headers = {\n",
    "        \"X-RapidAPI-Key\": API_KEY,\n",
    "        \"X-RapidAPI-Host\": \"api-nba-v1.p.rapidapi.com\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        r = requests.get(f\"{base_url}/{endpoint}\", \n",
    "                        headers=headers, \n",
    "                        params=params, \n",
    "                        timeout=10)\n",
    "        r.raise_for_status()\n",
    "        return r.json()\n",
    "    except Exception as e:\n",
    "        print(f\"Sorry, API issues: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_team_id(team_name):\n",
    "    resp = hit_api(\"teams\")\n",
    "    if not resp:\n",
    "        return None\n",
    "        \n",
    "    #loop through teams\n",
    "    for t in resp.get('response', []):\n",
    "        if team_name.lower() in t['name'].lower():\n",
    "            print(f\"Found {t['name']} (ID: {t['id']})\")\n",
    "            return t['id']\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093f9bf0",
   "metadata": {},
   "source": [
    "Output generation \n",
    "=================\n",
    "produces analysis-ready output in a directly consumable form. The primary output is neatly formatted CSV files with player statistics that have consistent column names and are in order to industry requirements. Files include metadata headers for generation timestamp, data source, and processing parameters for aiding version control. The exporter has robust file handling with correct permissions, atomic write patterns for preventing partial outputs, and parameterizable destination paths. The system normalizes data into forms for integrated database environments that map well into relational schemas. Output file naming is deterministic with team, season, and date information for easy organization. The exporter provides validation checks that files were written out in their entirety and correctly before reporting successful completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffea990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_to_csv(stats, team, season):\n",
    "    if not stats:\n",
    "        print(\"No stats to save!\")\n",
    "        return False\n",
    "    \n",
    "    # create output dir if needed\n",
    "    os.makedirs(STATS_DIR, exist_ok=True)\n",
    "    fname = f\"{team.lower().replace(' ', '_')}_{season}_stats.csv\"\n",
    "    fpath = os.path.join(STATS_DIR, fname)\n",
    "    \n",
    "    try:\n",
    "        with open(fpath, 'w', newline='') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=[\n",
    "                'name', 'ppg', 'rpg', 'apg', 'fg_pct', \n",
    "                'games_played', 'last_updated'\n",
    "            ])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(stats)\n",
    "        print(f\"\\nSaved everything to {fpath}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"CSV write failed: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2608b625",
   "metadata": {},
   "source": [
    "The flow \n",
    "=========\n",
    "of execution orchestrates all components into a single pipeline. Initialization loads and verifies the configuration while establishing necessary resources and connections. The collection gathering phase gathers roster information and game logs with chunking and pacing appropriate for high data sets. Processing transforms raw data into a processed state through validation, statistical computation, and quality check stages. Export generates permanent output while dropping temporary resources. The pipeline uses status monitoring with satisfactory progress and issue feedback in every operation. Error handling differentiates between transient errors (like network blips) that can be retried and fatal errors (like bad credentials) that require intervention by the user. The pipeline is designed for interactive use in exploratory analysis and programmatic integration into larger data pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99a64d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"\\nNBA Stats Grabber\")\n",
    "    print(\"================\\n\")\n",
    "    config = setup_config()\n",
    "    \n",
    "    # find team\n",
    "    print(f\"\\nLooking for {config['team_name']}...\")\n",
    "    team_id = get_team_id(config['team_name'])\n",
    "    if not team_id:\n",
    "        print(\"Can't find that team!\")\n",
    "        return\n",
    "    \n",
    "    # grab roster\n",
    "    roster = grab_players(team_id, config['season'])\n",
    "    if not roster:\n",
    "        print(\"No players found - something's wrong\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nFound {len(roster)} players to process...\\n\")\n",
    "    \n",
    "    # main processing loop\n",
    "    player_stats = []\n",
    "    for idx, player in enumerate(roster, 1):\n",
    "        f_name = player.get('firstname', '').strip()\n",
    "        l_name = player.get('lastname', '').strip()\n",
    "        full_name = f\"{f_name} {l_name}\" if f_name or l_name else \"Unknown\"\n",
    "        \n",
    "        pid = player.get('id')\n",
    "        if not pid:\n",
    "            print(f\"No ID for {full_name}, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"{idx}. Getting stats for {full_name}\", end=\"\", flush=True)\n",
    "        stats = get_player_stats(pid, full_name, config['season'])\n",
    "        \n",
    "        if stats:\n",
    "            player_stats.append(stats)\n",
    "            print(f\" -> {stats['ppg']} ppg, {stats['rpg']} rpg\")\n",
    "        else:\n",
    "            print(\" -> no stats found\")\n",
    "        if idx < len(roster):\n",
    "            time.sleep(config['delay'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8c5b9e",
   "metadata": {},
   "source": [
    "Output management\n",
    "======================\n",
    "Full status reporting\n",
    "\n",
    "There is top-level error handling to trap keyboard interrupts and other exceptions and provide courteous exit messages. The progress reporting offers immediate feedback for long-running operations - a minor but valuable feature for production utilities.\n",
    "This example illustrates how programming principles in the classroom grow into professional systems with an eye for reliability, maintainability, and actual-world limitations. Every piece could be expanded (adding database capability, additional statistics, etc.) without sacrificing the same level of professionalism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50162487",
   "metadata": {},
   "source": [
    "Conclusion and Next Steps\n",
    "===========================\n",
    "This workshop has equipped participants to build professional-grade sports analytics pipelines beyond classroom exercises. The techniques and themes demonstrated are not limited to basketball but to any data-intensive discipline requiring substantial collection, processing, and analysis of significant statistics. The pipeline's modular structure provides several natural extensions that would be excellent follow-up projects for students wishing to expand their knowledge.\n",
    "Expanding the statistical arsenal offers one beneficial area of enhancement. The system could include advanced defensive statistics like defensive rating or steal percentage, lineup analysis tracking group performance for given player pairings, or even prognostic model components projecting future performance from historical trends. Each further category of new statistics would support the principles of good statistical use while enhancing the system's value as an analytical tool.\n",
    "Technical add-ons would convert the pipeline into a more complex platform. Integration with a database would allow for permanent storage of historical statistics to enable longitudinal analysis. A visual layer could generate charts and reports from processed information. Automatic reporting capabilities could issue daily or weekly reports to coaching staff or the media. Web service encapsulation would expose access to the system's features remotely over REST APIs. These enhancements would demonstrate how analytical pipelines integrate into larger organizational contexts.\n",
    "Professional development techniques offer another space for growth. Facilitating a complete test environment with unit tests for each calculation module and integration tests for the whole pipeline would guarantee software engineering best practices. Performance benchmarking would identify areas for optimization throughout the data processing pipeline. An environment setup with continuous integration would demonstrate state-of-the-art DevOps best practices for analysis systems. Documentation generation would provide professional-grade reference material for system maintainers and end users.\n",
    "The knowledge acquired through this workshop has direct applications in the whole range of careers in sports technology. Teams' analytics departments value professionals who understand statistical methodologies and their reliable implementation. League information needs to be handled by engineers in the form of engaging visualizations and stories for media outlets. Fantasy sports and sports betting analysis require robust pipes that handle fast-evolving data. Talent evaluation relies on real-time, accurate statistics from player rating services. Perhaps most importantly, these trends are relevant to countless domains beyond sports - any field that deals with vast quantities of fast-changing data can learn from the same master engineering methods.\n",
    "The complete solution demonstrates how classroom programming concepts mature into industrial data systems by considering reliability, maintainability, and reality constraints. Students gain specific technical skills and the mindset to build production-quality analytical tools. This process of evolving from academic exercise to professional work is a critical milestone in any data-driven career path."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461ee707",
   "metadata": {},
   "source": [
    "Full Code Script\n",
    "=================\n",
    "\n",
    "NBA Player Statistics Grabber\n",
    "===============================\n",
    "\n",
    "A comprehensive tool to fetch, process, and analyze NBA player statistics from the API-NBA via RapidAPI.\n",
    "\n",
    "Features:\n",
    "- Can be configured either interactively or via creds.py\n",
    "- Fetches season averages for all players on a specified team\n",
    "- Handles API rate limiting with configurable delays\n",
    "- Calculates advanced statistics (PPG, RPG, APG, FG%)\n",
    "- Outputs clean CSV files with proper error handling\n",
    "- Provides progress tracking and verbose logging\n",
    "\n",
    "Usage Options:\n",
    "1. Interactive Mode:\n",
    "   - Run the script and follow the prompts\n",
    "   - Enter all configuration when prompted\n",
    "\n",
    "2. Manual Configuration:\n",
    "   - Set your RapidAPI key in creds.py\n",
    "   - Configure TEAM_NAME, SEASON, DELAY, and OUTPUT_DIR constants\n",
    "   - Run the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4455509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NBA Stats Grabber\n",
      "================\n",
      "\n",
      "Found API key in creds.py!\n",
      "\n",
      "Looking for Bulls...\n",
      "Found Chicago Bulls (ID: 6)\n",
      "\n",
      "Found 22 players to process...\n",
      "\n",
      "1. Getting stats for Alex Caruso -> 9.8 ppg, 3.7 rpg\n",
      "2. Getting stats for Torrey Craig -> 5.5 ppg, 4.0 rpg\n",
      "3. Getting stats for Jevon Carter -> 4.9 ppg, 0.8 rpg\n",
      "4. Getting stats for Coby White -> 19.0 ppg, 4.5 rpg\n",
      "5. Getting stats for Javonte Green -> 12.0 ppg, 6.9 rpg\n",
      "6. Getting stats for Patrick Williams -> 10.1 ppg, 3.8 rpg\n",
      "7. Getting stats for Ayo Dosunmu -> 12.1 ppg, 2.8 rpg\n",
      "8. Getting stats for Carlik Jones -> 2.0 ppg, 1.2 rpg\n",
      "9. Getting stats for Terry Taylor -> 1.9 ppg, 1.6 rpg\n",
      "10. Getting stats for Justin Lewis -> 2.0 ppg, 1.5 rpg\n",
      "11. Getting stats for Dalen Terry -> 3.0 ppg, 2.0 rpg\n",
      "12. Getting stats for Quenton Jackson -> 2.4 ppg, 1.1 rpg\n",
      "13. Getting stats for Onuralp Bitim -> 3.7 ppg, 1.3 rpg\n",
      "14. Getting stats for Henri Drell -> 1.6 ppg, 0.6 rpg\n",
      "15. Getting stats for Max Heidegger -> 1.0 ppg, 0.0 rpg\n",
      "16. Getting stats for Julian Phillips -> 2.4 ppg, 1.0 rpg\n",
      "17. Getting stats for Adama Sanogo -> 4.3 ppg, 4.0 rpg\n",
      "18. Getting stats for Andrew Funk -> 1.5 ppg, 0.5 rpg\n",
      "19. Getting stats for DeMar DeRozan -> 23.4 ppg, 4.2 rpg\n",
      "20. Getting stats for Nikola Vucevic -> 17.9 ppg, 10.4 rpg\n",
      "21. Getting stats for Andre Drummond -> 8.2 ppg, 9.0 rpg\n",
      "22. Getting stats for Zach LaVine -> 19.2 ppg, 4.9 rpg\n",
      "\n",
      "Saved everything to nba_stats\\bulls_2023_stats.csv\n",
      "\n",
      "All done! Got stats for 22 players\n",
      "\n",
      "Thanks for using my stats grabber!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "TEAM_DEFAULT = \"Bulls\"  # my team :)\n",
    "SEASON_DEFAULT = \"2023\"\n",
    "WAIT_TIME = 6\n",
    "STATS_DIR = \"nba_stats\"\n",
    "\n",
    "# grab API key from creds.py\n",
    "try:\n",
    "    from creds import RAPIDAPI_KEY\n",
    "    API_KEY = RAPIDAPI_KEY\n",
    "except ImportError:\n",
    "    API_KEY = None \n",
    "\n",
    "def setup_config():\n",
    "    settings = {}\n",
    "    if not API_KEY:\n",
    "        settings['api_key'] = input(\"Drop your RapidAPI key here: \").strip()\n",
    "        if not settings['api_key']:\n",
    "            print(\"Can't continue without an API key :(\")\n",
    "            exit()\n",
    "    else:\n",
    "        settings['api_key'] = API_KEY\n",
    "        print(\"Found API key in creds.py!\")\n",
    "    \n",
    "    # get team\n",
    "    team = input(f\"Which team? (default: {TEAM_DEFAULT}): \").strip()\n",
    "    settings['team_name'] = team or TEAM_DEFAULT\n",
    "    \n",
    "    # season input validation\n",
    "    while True:\n",
    "        season = input(f\"What season? (default: {SEASON_DEFAULT}): \").strip() or SEASON_DEFAULT\n",
    "        if len(season) == 4 and season.isdigit():\n",
    "            settings['season'] = season\n",
    "            break\n",
    "        print(\"Need a 4-digit year!\")\n",
    "    \n",
    "    # api delay\n",
    "    while True:\n",
    "        delay = input(f\"Seconds between API calls (default: {WAIT_TIME}): \").strip() or str(WAIT_TIME)\n",
    "        try:\n",
    "            settings['delay'] = max(0.5, float(delay))  # at least half a second\n",
    "            break\n",
    "        except ValueError:\n",
    "            print(\"Numbers only please!\")\n",
    "    \n",
    "    return settings\n",
    "\n",
    "def hit_api(endpoint, params=None):\n",
    "    # basic api wrapper\n",
    "    base_url = \"https://api-nba-v1.p.rapidapi.com\"\n",
    "    headers = {\n",
    "        \"X-RapidAPI-Key\": API_KEY,\n",
    "        \"X-RapidAPI-Host\": \"api-nba-v1.p.rapidapi.com\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        r = requests.get(f\"{base_url}/{endpoint}\", \n",
    "                        headers=headers, \n",
    "                        params=params, \n",
    "                        timeout=10)\n",
    "        r.raise_for_status()\n",
    "        return r.json()\n",
    "    except Exception as e:\n",
    "        print(f\"Sorry, API issues: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_team_id(team_name):\n",
    "    resp = hit_api(\"teams\")\n",
    "    if not resp:\n",
    "        return None\n",
    "        \n",
    "    #loop through teams\n",
    "    for t in resp.get('response', []):\n",
    "        if team_name.lower() in t['name'].lower():\n",
    "            print(f\"Found {t['name']} (ID: {t['id']})\")\n",
    "            return t['id']\n",
    "    return None\n",
    "\n",
    "def grab_players(team_id, season):\n",
    "    #just get all players for a team\n",
    "    params = {\"team\": team_id, \"season\": season}\n",
    "    resp = hit_api(\"players\", params)\n",
    "    return resp.get('response', []) if resp else []\n",
    "\n",
    "def get_player_stats(pid, pname, season):\n",
    "    params = {\"id\": pid, \"season\": season}\n",
    "    resp = hit_api(\"players/statistics\", params)\n",
    "    if not resp:\n",
    "        return None\n",
    "    \n",
    "    # filter\n",
    "    games = resp.get('response', [])\n",
    "    real_games = [g for g in games if g.get('min') not in [None, \"00:00\", \"\"]]\n",
    "    \n",
    "    if not real_games:\n",
    "        print(f\"Looks like {pname} didn't play\")\n",
    "        return None\n",
    "    \n",
    "    total_pts = sum(float(g.get('points', 0)) for g in real_games)\n",
    "    total_reb = sum(float(g.get('totReb', 0)) for g in real_games)\n",
    "    total_ast = sum(float(g.get('assists', 0)) for g in real_games)\n",
    "    made = sum(float(g.get('fgm', 0)) for g in real_games)\n",
    "    attempted = sum(float(g.get('fga', 0)) for g in real_games)\n",
    "    \n",
    "    return {\n",
    "        'name': pname,\n",
    "        'ppg': round(total_pts / len(real_games), 1),\n",
    "        'rpg': round(total_reb / len(real_games), 1),\n",
    "        'apg': round(total_ast / len(real_games), 1),\n",
    "        'fg_pct': round(made / attempted, 3) if attempted > 0 else 0.0,\n",
    "        'games_played': len(real_games),\n",
    "        'last_updated': datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    }\n",
    "\n",
    "def dump_to_csv(stats, team, season):\n",
    "    if not stats:\n",
    "        print(\"No stats to save!\")\n",
    "        return False\n",
    "    \n",
    "    # create output dir if needed\n",
    "    os.makedirs(STATS_DIR, exist_ok=True)\n",
    "    fname = f\"{team.lower().replace(' ', '_')}_{season}_stats.csv\"\n",
    "    fpath = os.path.join(STATS_DIR, fname)\n",
    "    \n",
    "    try:\n",
    "        with open(fpath, 'w', newline='') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=[\n",
    "                'name', 'ppg', 'rpg', 'apg', 'fg_pct', \n",
    "                'games_played', 'last_updated'\n",
    "            ])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(stats)\n",
    "        print(f\"\\nSaved everything to {fpath}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"CSV write failed: {e}\")\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    print(\"\\nNBA Stats Grabber\")\n",
    "    print(\"================\\n\")\n",
    "    config = setup_config()\n",
    "    \n",
    "    # find team\n",
    "    print(f\"\\nLooking for {config['team_name']}...\")\n",
    "    team_id = get_team_id(config['team_name'])\n",
    "    if not team_id:\n",
    "        print(\"Can't find that team!\")\n",
    "        return\n",
    "    \n",
    "    # grab roster\n",
    "    roster = grab_players(team_id, config['season'])\n",
    "    if not roster:\n",
    "        print(\"No players found - something's wrong\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nFound {len(roster)} players to process...\\n\")\n",
    "    \n",
    "    # main processing loop\n",
    "    player_stats = []\n",
    "    for idx, player in enumerate(roster, 1):\n",
    "        # cleanup player name\n",
    "        f_name = player.get('firstname', '').strip()\n",
    "        l_name = player.get('lastname', '').strip()\n",
    "        full_name = f\"{f_name} {l_name}\" if f_name or l_name else \"Unknown\"\n",
    "        \n",
    "        pid = player.get('id')\n",
    "        if not pid:\n",
    "            print(f\"No ID for {full_name}, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"{idx}. Getting stats for {full_name}\", end=\"\", flush=True)\n",
    "        stats = get_player_stats(pid, full_name, config['season'])\n",
    "        \n",
    "        if stats:\n",
    "            player_stats.append(stats)\n",
    "            print(f\" -> {stats['ppg']} ppg, {stats['rpg']} rpg\")\n",
    "        else:\n",
    "            print(\" -> no stats found\")\n",
    "            \n",
    "        # don't hammer the api\n",
    "        if idx < len(roster):\n",
    "            time.sleep(config['delay'])\n",
    "    \n",
    "    # save everything\n",
    "    if player_stats:\n",
    "        dump_to_csv(player_stats, config['team_name'], config['season'])\n",
    "        print(f\"\\nAll done! Got stats for {len(player_stats)} players\")\n",
    "    else:\n",
    "        print(\"\\nSorry, couldn't get any stats\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nOk, stopping!\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nSomething broke: {e}\")\n",
    "    finally:\n",
    "        print(\"\\nThanks for using my stats grabber!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
